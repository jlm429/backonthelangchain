{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41559c18-9d4a-48c0-8bb6-8f6a703691c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on code from https://github.com/emarco177/ice_breaker\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3d2645c-a8e0-4970-8ce0-47a0d451d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Pydantic model to structure the LLM output\n",
    "# It includes a short summary and a list of interesting facts\n",
    "class Summary(BaseModel):\n",
    "    summary: str = Field(description=\"summary\")\n",
    "    facts: List[str] = Field(description=\"interesting facts about them\")\n",
    "\n",
    "    # Utility method to convert the model to a dictionary (optional use)\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return {\"summary\": self.summary, \"facts\": self.facts}\n",
    "\n",
    "# Create a LangChain-compatible parser that expects output matching the Summary model\n",
    "summary_parser = PydanticOutputParser(pydantic_object=Summary)\n",
    "\n",
    "# Use Tavily to search GitHub for a person's profile based on their name/location\n",
    "# Returns the best result's URL and content (if found), otherwise returns None\n",
    "def get_profile_url_and_content(name: str):\n",
    "    \"\"\"Search GitHub using Tavily and return the best match (url + content).\"\"\"\n",
    "    search = TavilySearchResults()\n",
    "    results = search.invoke(f\"{name} GitHub site:github.com\")\n",
    "\n",
    "    if results and isinstance(results, list):\n",
    "        best = results[0]\n",
    "        return best[\"url\"], best[\"content\"]\n",
    "    return None, None\n",
    "\n",
    "# Uses a prompt + OpenAI LLM + Pydantic parser chain to generate a structured profile summary\n",
    "def summarize_profile(info: str) -> str:\n",
    "    \"\"\"Uses LLM to summarize profile text and extract two interesting facts.\"\"\"\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "\n",
    "    # Template tells the LLM what kind of response is expected\n",
    "    summary_template = \"\"\"\n",
    "    Given the following GitHub profile content:\n",
    "    {information}\n",
    "\n",
    "    Return:\n",
    "    1. A short summary of the person\n",
    "    2. Two interesting facts about them\n",
    "    \\n{format_instructions}\n",
    "    \"\"\"\n",
    "\n",
    "    # Define a prompt that takes both the GitHub content and format instructions\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"information\", \"format_instructions\"],\n",
    "        template=summary_template,\n",
    "    )\n",
    "\n",
    "    # Chain together the prompt, LLM, and output parser\n",
    "    chain = prompt_template | llm | summary_parser\n",
    "\n",
    "    # Invoke the chain with the profile text and required format instructions\n",
    "    return chain.invoke(\n",
    "        {\n",
    "            \"information\": info,\n",
    "            \"format_instructions\": summary_parser.get_format_instructions(),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d232078b-631b-4bfa-bc31-a6dcfc072050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LangChain with Tavily and OpenAI to find a person's GitHub URL and summarize their public profile.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the person's name and location (e.g., 'John Mansfield Ithaca NY'):  John Mansfield Ithaca, NY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GitHub URL: https://github.com/jlm429\n",
      "\n",
      "summary='John Mansfield, known by the username jlm429, is an accomplished GitHub user with notable achievements in the open-source community.' facts=[\"He has received the 'Starstruck' achievement, indicating a significant level of engagement on GitHub.\", \"He is recognized as an 'Arctic Code Vault Contributor', highlighting his contributions to projects that are preserved for future generations.\"]\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from a .env file (e.g., OpenAI API key)\n",
    "load_dotenv()\n",
    "\n",
    "# Prompt the user and explain the purpose of the script\n",
    "print(\"Using LangChain with Tavily and OpenAI to find a person's GitHub URL and summarize their public profile.\")\n",
    "\n",
    "# Get user input: a person's name and location to help guide the search\n",
    "name = input(\"Enter the person's name and location (e.g., 'John Mansfield Ithaca NY'): \")\n",
    "\n",
    "# Use Tavily search to find the best-matching GitHub profile and retrieve its content\n",
    "github_url, profile_content = get_profile_url_and_content(name)\n",
    "\n",
    "# If a GitHub URL and profile content were successfully retrieved\n",
    "if github_url and profile_content:\n",
    "    print(f\"Found GitHub URL: {github_url}\\n\")\n",
    "\n",
    "    # Use an LLM to summarize the GitHub profile content and extract interesting facts\n",
    "    summary = summarize_profile(profile_content)\n",
    "\n",
    "    # Print the structured summary (this may be a Pydantic object)\n",
    "    print(summary)\n",
    "else:\n",
    "    # Inform the user if no profile was found\n",
    "    print(\"No GitHub profile found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f5e6192-a97f-41b4-9e49-0a3fb0699946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### GitHub Summary\n",
       "John Mansfield, known by the username jlm429, is an accomplished GitHub user with notable achievements in the open-source community."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Interesting Facts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- He has received the 'Starstruck' achievement, indicating a significant level of engagement on GitHub."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- He is recognized as an 'Arctic Code Vault Contributor', highlighting his contributions to projects that are preserved for future generations."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the parsed summary and interesting facts from the GitHub profile\n",
    "# in a nicely formatted Markdown layout within the Jupyter notebook.\n",
    "# Uses IPython's display and Markdown to render clean, readable output.\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(f\"### GitHub Summary\\n{summary.summary}\"))\n",
    "display(Markdown(\"### Interesting Facts\"))\n",
    "for fact in summary.facts:\n",
    "    display(Markdown(f\"- {fact}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27541355-00d2-4130-bd74-c7cd0c23675c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain (Pipenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
