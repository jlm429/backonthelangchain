{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e99e558-869d-46ec-86ae-990780cef86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import textwrap\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain loaders, splitters, and vector store\n",
    "from langchain_community.document_loaders import PyPDFLoader, YoutubeLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter \n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# LangChain chains & prompts\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain import hub\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9152190-552f-47b4-8085-5667cd4422ad",
   "metadata": {},
   "source": [
    "### Ingesting ICA Resources into Pinecone\n",
    "\n",
    "This cell prepares and ingests documents related to **Independent Component Analysis (ICA)** into the Pinecone vector store for retrieval-based QA.\n",
    "\n",
    "1. **Load PDFs**  \n",
    "   We load one or more PDF documents using `PyPDFLoader`. In this case, we're using `fastICA.pdf`, which contains academic content on ICA.\n",
    "\n",
    "2. **Load YouTube Transcript**  \n",
    "   The transcript from a YouTube lecture (Stanford Online) is loaded using `YoutubeLoader`. The transcript is treated as a document and will be chunked like any other source.\n",
    "\n",
    "3. **Combine All Documents**  \n",
    "   All loaded documents (PDFs + YouTube transcript) are merged into a single list so they can be processed together.\n",
    "\n",
    "4. **✂Chunking**  \n",
    "   The combined content is split into smaller, overlapping chunks using `RecursiveCharacterTextSplitter` to preserve context. Each chunk is ~500 characters with 100-character overlap to improve retrieval fidelity.\n",
    "\n",
    "5. **Generate Embeddings**  \n",
    "   Each chunk is transformed into a high-dimensional embedding using OpenAI’s embedding model.\n",
    "\n",
    "6. **Ingest into Pinecone**  \n",
    "   Chunks are filtered to avoid exceeding Pinecone's per-vector metadata limits (~40KB), then stored in the Pinecone index. This allows for fast similarity-based retrieval later.\n",
    "\n",
    "Once complete, we can run queries over this embedded corpus and retrieve relevant chunks to answer ICA-related questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7e6f412-4836-45f9-a3b8-e9ea3e4beb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting...\n",
      "Created 364 chunks\n",
      "Ingesting into Pinecone...\n",
      "Ingestion complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Load PDFs ---\n",
    "pdf_paths = [\"fastICA.pdf\"]\n",
    "pdf_docs = []\n",
    "for path in pdf_paths:\n",
    "    loader = PyPDFLoader(path)\n",
    "    pdf_docs.extend(loader.load())\n",
    "\n",
    "# --- Load YouTube transcript ---\n",
    "# Make sure the video has captions or transcript available\n",
    "youtube_url = \"https://www.youtube.com/watch?v=YQA9lLdLig8&ab_channel=StanfordOnline\" \n",
    "yt_loader = YoutubeLoader.from_youtube_url(youtube_url, add_video_info=False)\n",
    "yt_docs = yt_loader.load()\n",
    "\n",
    "# --- Combine all docs ---\n",
    "all_docs = pdf_docs + yt_docs\n",
    "\n",
    "print(\"Splitting...\")\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "texts = splitter.split_documents(all_docs)\n",
    "print(f\"Created {len(texts)} chunks\")\n",
    "\n",
    "# --- Embeddings and Pinecone ingestion ---\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "print(\"Ingesting into Pinecone...\")\n",
    "texts = [doc for doc in texts if len(doc.page_content.encode(\"utf-8\")) < 3000]\n",
    "PineconeVectorStore.from_texts(\n",
    "    [doc.page_content for doc in texts],\n",
    "    embedding=embeddings,\n",
    "    index_name=os.environ[\"INDEX_NAME\"]\n",
    ")\n",
    "print(\"Ingestion complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9503a75-57a5-421d-9b50-d7fe5cbc522b",
   "metadata": {},
   "source": [
    "### Ask Questions About ICA Using RAG\n",
    "\n",
    "This cell allows the user to input a natural language question about **Independent Component Analysis (ICA)** and generates an answer based on the previously ingested documents (PDF + YouTube transcript).\n",
    "\n",
    "1. **Prompt the User**  \n",
    "   The user is asked to type a question (e.g., *\"What is the cocktail-party problem?\"*).\n",
    "\n",
    "2. **Load Embedding Model and Vector Store**  \n",
    "   - The same OpenAI embedding model used during ingestion is reloaded.\n",
    "   - The Pinecone vector store is connected so we can retrieve relevant document chunks.\n",
    "\n",
    "3. **Create a Retrieval-Augmented Generation (RAG) Chain**  \n",
    "   - A `retrieval_chain` is created by combining a document retriever (from Pinecone) and a prompt-response LLM chain.\n",
    "   - The system message encourages the LLM to **base its answer primarily on the retrieved documents**, and discourages hallucinations.\n",
    "   - The retriever uses **vector similarity** to fetch the 5 most relevant document chunks based on the user’s query.\n",
    "\n",
    "4. **Generate and Display Answer**  \n",
    "   - The chain is invoked with the user’s question.\n",
    "   - The resulting answer is printed.\n",
    "   - Additionally, the document chunks used to generate the answer are shown under **“Context Chunks Used”** to provide transparency.\n",
    "\n",
    "This setup allows us to ask detailed, contextual questions about ICA theory, applications, or examples, leveraging both text and transcript data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32cb2f76-e1ce-47c1-b3c6-8159b1e71550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter question about ICA:  please explain the cocktail-party problem\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vector store and models...\n",
      "Retrieving and generating answer...\n",
      "\n",
      "### Answer:\n",
      "\n",
      "The cocktail-party problem refers to a scenario where multiple sound sources are mixed together,\n",
      "like at a party where many people are speaking simultaneously. In this situation, the goal is to\n",
      "separate and isolate the individual sound sources from the mixed signals recorded by microphones.\n",
      "This problem is analogous to trying to pick out and understand individual voices in a crowded and\n",
      "noisy room.  To address the cocktail-party problem, researchers use techniques like Independent\n",
      "Component Analysis (ICA) to estimate the original sound sources based on the mixed signals received\n",
      "by microphones. By analyzing the recorded signals mathematically, it is possible to separate the\n",
      "combined voices and extract the individual speech signals, ultimately reconstructing the original\n",
      "sources.\n",
      "\n",
      "---\n",
      "\n",
      "### Context Chunks Used:\n",
      "\n",
      "**Chunk 1:**\n",
      "\n",
      ". And the goal is to find the matrix W, uh, which should hopefully be A inverse, um, so that SI is W\n",
      "times X recovered the original sources. Uh, and we're going to use these W1 up through WN to\n",
      "represent the rows of this matrix W. Yeah. [inaudible]. Uh, oh yes you're right. Thank you. Right.\n",
      "Okay. Thank you. Okay. [NOISE] So, um, [NOISE] last time we had [NOISE]. All right. So remember this\n",
      "is a picture of the Cocktail party problem\n",
      "\n",
      "---\n",
      "\n",
      "**Chunk 2:**\n",
      "\n",
      "as a linear equation: x1(t) = a11s1 + a12s2 (1) x2(t) = a21s1 + a22s2 (2) where a11, a12, a21,\n",
      "anda22 are some parameters that depend on the distances of the microphones from the speakers. It\n",
      "would be very useful if you could now estimate the two original speech signalss1(t) and s2(t), using\n",
      "only the recorded signalsx1(t) and x2(t). This is called thecocktail-party problem. For the time\n",
      "being, we omit any time delays or other extra factors from our simpliﬁed mixing model.\n",
      "\n",
      "---\n",
      "\n",
      "**Chunk 3:**\n",
      "\n",
      ". So the analogy to the cocktail party problem, the, um, overlapping speakers' voices is that, you\n",
      "know, your- your brain [NOISE] does a lot of things at the same time, right? Your brain helps\n",
      "regulate your heartbeat, um, part of your brain does that, another part of your brain, you know,\n",
      "makes your eyes blink every now and then, another part of your brain- part of your brain is also\n",
      "responsible for making sure that you breathe, another part of your brain is responsible to thinking\n",
      "about machine\n",
      "\n",
      "---\n",
      "\n",
      "**Chunk 4:**\n",
      "\n",
      "reversed, but this has no signiﬁcance.) Independent component analysis was originally developed to\n",
      "deal with problems that are closely related to the cocktail-party problem. Since the recent increase\n",
      "of interest in ICA, it has become clear that this principle has a lot of other interesting\n",
      "applications as well. Consider, for example, electrical recordings of brain activity as given by an\n",
      "electroencephalogram (EEG). The\n",
      "\n",
      "---\n",
      "\n",
      "**Chunk 5:**\n",
      "\n",
      ". So think of there as, um, imagine that you have a, you know, cocktail party in your head, right?\n",
      "So many overlapping voices, so this is now voices in your head, uh, just going back, but one- one-\n",
      "one part of your brain is saying, all right heart, go and beat, heart go and beat, heart go and\n",
      "beat, and another part of the brain is saying, hey, breathe in and breathe out, breathe in and\n",
      "breathe out, another part of the brain is ooh, you know\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Prompt user for query ---\n",
    "query = input(\"Enter question about ICA: \").strip()\n",
    "\n",
    "print(\"Loading vector store and models...\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index_name=os.environ[\"INDEX_NAME\"],\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# --- Create retrieval chain ---\n",
    "retrieval_qa_chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are an expert assistant answering questions using the context below. \"\n",
    "     \"Base your answer primarily on the provided documents. \"\n",
    "     \"If relevant information is found in the context, use it to answer as clearly and helpfully as possible. \"\n",
    "     \"If nothing useful is found, you may respond with 'The answer is not available in the provided documents.'\"),\n",
    "    (\"human\", \"Context:\\n{context}\\n\\nQuestion:\\n{input}\")\n",
    "])\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, retrieval_qa_chat_prompt)\n",
    "retrieval_chain = create_retrieval_chain(\n",
    "    retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5}),\n",
    "    combine_docs_chain=combine_docs_chain\n",
    ")\n",
    "\n",
    "# --- Run the query ---\n",
    "print(\"Retrieving and generating answer...\\n\")\n",
    "result = retrieval_chain.invoke({\"input\": query})\n",
    "\n",
    "# --- Format and print Markdown-style output ---\n",
    "answer = result.get(\"answer\", \"[No answer generated]\")\n",
    "sources = result.get(\"context\", [])\n",
    "\n",
    "print(\"### Answer:\\n\")\n",
    "print(textwrap.fill(answer, width=100))\n",
    "\n",
    "if sources:\n",
    "    print(\"\\n---\\n\")\n",
    "    print(\"### Context Chunks Used:\\n\")\n",
    "    for i, doc in enumerate(sources):\n",
    "        print(f\"**Chunk {i+1}:**\\n\")\n",
    "        print(textwrap.fill(doc.page_content.strip(), width=100))\n",
    "        print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bd2875-22df-47a6-9a2b-159b6b6324e3",
   "metadata": {},
   "source": [
    "### Displaying the Answer in Markdown Format\n",
    "\n",
    "This cell formats the output using **Markdown**, but it could be adapted for use with any frontend. \n",
    "\n",
    "1. **Extract Results**  \n",
    "   Retrieves the answer generated by the retrieval-augmented chain and the document chunks (`context`) used to produce it.\n",
    "\n",
    "2. **Display Answer**  \n",
    "   Uses `IPython.display.Markdown` to render the final answer under a bold \"Answer\" heading.\n",
    "\n",
    "3. **Display Source Chunks**  \n",
    "   If any relevant document chunks were used:\n",
    "   - Each chunk is shortened to its first ~40 words.\n",
    "   - Chunks are numbered and displayed in a clean, bullet-style list.\n",
    "   - This gives users transparency into *where* the answer came from without overwhelming them with full documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b153116-82ac-4624-8773-896ff4049c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 🤖 Answer\n",
       "\n",
       "The cocktail-party problem refers to a scenario where multiple sound sources are mixed together, like at a party where many people are speaking simultaneously. In this situation, the goal is to separate and isolate the individual sound sources from the mixed signals recorded by microphones. This problem is analogous to trying to pick out and understand individual voices in a crowded and noisy room.\n",
       "\n",
       "To address the cocktail-party problem, researchers use techniques like Independent Component Analysis (ICA) to estimate the original sound sources based on the mixed signals received by microphones. By analyzing the recorded signals mathematically, it is possible to separate the combined voices and extract the individual speech signals, ultimately reconstructing the original sources."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "---\n",
       "\n",
       "### Context Chunks Used\n",
       "\n",
       "- **Chunk 1**: . And the goal is to find the matrix W, uh, which should hopefully be A inverse, um, so that SI is W times X recovered the original sources. Uh, and we're going to use these W1 up through WN...\n",
       "- **Chunk 2**: as a linear equation: x1(t) = a11s1 + a12s2 (1) x2(t) = a21s1 + a22s2 (2) where a11, a12, a21, anda22 are some parameters that depend on the distances of the microphones from the speakers. It would be very useful...\n",
       "- **Chunk 3**: . So the analogy to the cocktail party problem, the, um, overlapping speakers' voices is that, you know, your- your brain [NOISE] does a lot of things at the same time, right? Your brain helps regulate your heartbeat, um, part...\n",
       "- **Chunk 4**: reversed, but this has no signiﬁcance.) Independent component analysis was originally developed to deal with problems that are closely related to the cocktail-party problem. Since the recent increase of interest in ICA, it has become clear that this principle has...\n",
       "- **Chunk 5**: . So think of there as, um, imagine that you have a, you know, cocktail party in your head, right? So many overlapping voices, so this is now voices in your head, uh, just going back, but one- one- one..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# --- Format and print Markdown-style output ---\n",
    "answer = result.get(\"answer\", \"[No answer generated]\")\n",
    "sources = result.get(\"context\", [])\n",
    "\n",
    "# Display the answer in Markdown\n",
    "display(Markdown(f\"### 🤖 Answer\\n\\n{answer.strip()}\"))\n",
    "\n",
    "if sources:\n",
    "    md_chunks = [\"\\n---\\n\", \"### Context Chunks Used\\n\"]\n",
    "    for i, doc in enumerate(sources):\n",
    "        content = doc.page_content.strip().replace(\"\\n\", \" \")\n",
    "        short = \" \".join(content.split()[:40]) + (\"...\" if len(content.split()) > 40 else \"\")\n",
    "        md_chunks.append(f\"- **Chunk {i+1}**: {short}\")\n",
    "    display(Markdown(\"\\n\".join(md_chunks)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f3fa6a-98ef-49ff-9fb0-dcb50dd16588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain (Pipenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
